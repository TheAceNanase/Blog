<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Scrapy入门 - 💗Nanase</title><meta name="Description" content=""><meta property="og:title" content="Scrapy入门" />
<meta property="og:description" content="Scrapy爬虫框架入门 Scrapy概述 Scrapy是Python开发的一个非常流行的网络爬虫框架，可以用来抓取Web站点并从页面中提取结构" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://www.nishinonanase.xyz/scrapy%E5%85%A5%E9%97%A8/" />
<meta property="og:image" content="http://www.nishinonanase.xyz/logo.png"/>
<meta property="article:published_time" content="2017-01-15T17:20:15+08:00" />
<meta property="article:modified_time" content="2017-01-15T17:20:15+08:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://www.nishinonanase.xyz/logo.png"/>

<meta name="twitter:title" content="Scrapy入门"/>
<meta name="twitter:description" content="Scrapy爬虫框架入门 Scrapy概述 Scrapy是Python开发的一个非常流行的网络爬虫框架，可以用来抓取Web站点并从页面中提取结构"/>
<meta name="application-name" content="💗Nanase">
<meta name="apple-mobile-web-app-title" content="💗Nanase"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://www.nishinonanase.xyz/scrapy%E5%85%A5%E9%97%A8/" /><link rel="prev" href="http://www.nishinonanase.xyz/gil%E5%85%A8%E5%B1%80%E8%A7%A3%E9%87%8A%E5%99%A8%E9%94%81/" /><link rel="next" href="http://www.nishinonanase.xyz/jwt%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Scrapy入门",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/www.nishinonanase.xyz\/scrapy%E5%85%A5%E9%97%A8\/"
        },"genre": "posts","keywords": "技术要点, 爬虫","wordcount":  2674 ,
        "url": "http:\/\/www.nishinonanase.xyz\/scrapy%E5%85%A5%E9%97%A8\/","datePublished": "2017-01-15T17:20:15+08:00","dateModified": "2017-01-15T17:20:15+08:00","publisher": {
            "@type": "Organization",
            "name": "Nanase","logo": "http:\/\/www.nishinonanase.xyz\/images\/avatar.png"},"author": {
                "@type": "Person",
                "name": "Nanase"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : '' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="💗Nanase">💗Nanase</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 🍑全部文章 </a><a class="menu-item" href="/tags/"> 🍊标签 </a><a class="menu-item" href="/categories/"> 🍓分类 </a><a class="menu-item" href="/about/"> 🥝关于 </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="💗Nanase">💗Nanase</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">🍑全部文章</a><a class="menu-item" href="/tags/" title="">🍊标签</a><a class="menu-item" href="/categories/" title="">🍓分类</a><a class="menu-item" href="/about/" title="">🥝关于</a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content always-active" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Scrapy入门</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>Nanase</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9/"><i class="far fa-folder fa-fw"></i>技术要点</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2017-01-15">2017-01-15</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 2674 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 6 分钟&nbsp;<span id="/scrapy%E5%85%A5%E9%97%A8/" class="leancloud_visitors" data-flag-title="Scrapy入门">
                        <i class="far fa-eye fa-fw"></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;次阅读
                    </span>&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#scrapy爬虫框架入门">Scrapy爬虫框架入门</a>
          <ul>
            <li><a href="#scrapy概述">Scrapy概述</a>
              <ul>
                <li><a href="#组件">组件</a></li>
                <li><a href="#数据处理流程">数据处理流程</a></li>
              </ul>
            </li>
            <li><a href="#安装和使用scrapy">安装和使用Scrapy</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="scrapy爬虫框架入门">Scrapy爬虫框架入门</h2>
<h3 id="scrapy概述">Scrapy概述</h3>
<p>Scrapy是Python开发的一个非常流行的网络爬虫框架，可以用来抓取Web站点并从页面中提取结构化的数据，被广泛的用于数据挖掘、数据监测和自动化测试等领域。下图展示了Scrapy的基本架构，其中包含了主要组件和系统的数据处理流程（图中带数字的红色箭头）。</p>
<h4 id="组件">组件</h4>
<ol>
<li>Scrapy引擎（Engine）：Scrapy引擎是用来控制整个系统的数据处理流程。</li>
<li>调度器（Scheduler）：调度器从Scrapy引擎接受请求并排序列入队列，并在Scrapy引擎发出请求后返还给它们。</li>
<li>下载器（Downloader）：下载器的主要职责是抓取网页并将网页内容返还给蜘蛛（Spiders）。</li>
<li>蜘蛛（Spiders）：蜘蛛是有Scrapy用户自定义的用来解析网页并抓取特定URL返回的内容的类，每个蜘蛛都能处理一个域名或一组域名，简单的说就是用来定义特定网站的抓取和解析规则。</li>
<li>条目管道（Item Pipeline）：条目管道的主要责任是负责处理有蜘蛛从网页中抽取的数据条目，它的主要任务是清理、验证和存储数据。当页面被蜘蛛解析后，将被发送到条目管道，并经过几个特定的次序处理数据。每个条目管道组件都是一个Python类，它们获取了数据条目并执行对数据条目进行处理的方法，同时还需要确定是否需要在条目管道中继续执行下一步或是直接丢弃掉不处理。条目管道通常执行的任务有：清理HTML数据、验证解析到的数据（检查条目是否包含必要的字段）、检查是不是重复数据（如果重复就丢弃）、将解析到的数据存储到数据库（关系型数据库或NoSQL数据库）中。</li>
<li>中间件（Middlewares）：中间件是介于Scrapy引擎和其他组件之间的一个钩子框架，主要是为了提供自定义的代码来拓展Scrapy的功能，包括下载器中间件和蜘蛛中间件。</li>
</ol>
<h4 id="数据处理流程">数据处理流程</h4>
<p>Scrapy的整个数据处理流程由Scrapy引擎进行控制，通常的运转流程包括以下的步骤：</p>
<ol>
<li>
<p>引擎询问蜘蛛需要处理哪个网站，并让蜘蛛将第一个需要处理的URL交给它。</p>
</li>
<li>
<p>引擎让调度器将需要处理的URL放在队列中。</p>
</li>
<li>
<p>引擎从调度那获取接下来进行爬取的页面。</p>
</li>
<li>
<p>调度将下一个爬取的URL返回给引擎，引擎将它通过下载中间件发送到下载器。</p>
</li>
<li>
<p>当网页被下载器下载完成以后，响应内容通过下载中间件被发送到引擎；如果下载失败了，引擎会通知调度器记录这个URL，待会再重新下载。</p>
</li>
<li>
<p>引擎收到下载器的响应并将它通过蜘蛛中间件发送到蜘蛛进行处理。</p>
</li>
<li>
<p>蜘蛛处理响应并返回爬取到的数据条目，此外还要将需要跟进的新的URL发送给引擎。</p>
</li>
<li>
<p>引擎将抓取到的数据条目送入条目管道，把新的URL发送给调度器放入队列中。</p>
</li>
</ol>
<p>上述操作中的2-8步会一直重复直到调度器中没有需要请求的URL，爬虫停止工作。</p>
<h3 id="安装和使用scrapy">安装和使用Scrapy</h3>
<p>可以先创建虚拟环境并在虚拟环境下使用pip安装scrapy。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-Shell" data-lang="Shell">
</code></pre></td></tr></table>
</div>
</div><p>项目的目录结构如下图所示。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-Shell" data-lang="Shell"><span class="o">(</span>venv<span class="o">)</span> $ tree
.
<span class="p">|</span>____ scrapy.cfg
<span class="p">|</span>____ douban
<span class="p">|</span> <span class="p">|</span>____ spiders
<span class="p">|</span> <span class="p">|</span> <span class="p">|</span>____ __init__.py
<span class="p">|</span> <span class="p">|</span> <span class="p">|</span>____ __pycache__
<span class="p">|</span> <span class="p">|</span>____ __init__.py
<span class="p">|</span> <span class="p">|</span>____ __pycache__
<span class="p">|</span> <span class="p">|</span>____ middlewares.py
<span class="p">|</span> <span class="p">|</span>____ settings.py
<span class="p">|</span> <span class="p">|</span>____ items.py
<span class="p">|</span> <span class="p">|</span>____ pipelines.py
</code></pre></td></tr></table>
</div>
</div><blockquote>
<p>说明：Windows系统的命令行提示符下有tree命令，但是Linux和MacOS的终端是没有tree命令的，可以用下面给出的命令来定义tree命令，其实是对find命令进行了定制并别名为tree。</p>
<p><code>alias tree=&quot;find . -print | sed -e 's;[^/]*/;|____;g;s;____|; |;g'&quot;</code></p>
<p>Linux系统也可以通过yum或其他的包管理工具来安装tree。</p>
<p><code>yum install tree</code></p>
</blockquote>
<p>根据刚才描述的数据处理流程，基本上需要我们做的有以下几件事情：</p>
<ol>
<li>
<p>在items.py文件中定义字段，这些字段用来保存数据，方便后续的操作。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-Python" data-lang="Python"><span class="c1"># -*- coding: utf-8 -*-</span>
   
<span class="c1"># Define here the models for your scraped items</span>
<span class="c1">#</span>
<span class="c1"># See documentation in:</span>
<span class="c1"># https://doc.scrapy.org/en/latest/topics/items.html</span>
   
<span class="kn">import</span> <span class="nn">scrapy</span>
   
   
<span class="k">class</span> <span class="nc">DoubanItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
   
    <span class="n">name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">year</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">director</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">classification</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">actor</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>在spiders文件夹中编写自己的爬虫。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-Shell" data-lang="Shell"><span class="o">(</span>venv<span class="o">)</span> $ scrapy genspider movie movie.douban.com --template<span class="o">=</span>crawl
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-Python" data-lang="Python"><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">Selector</span>
<span class="kn">from</span> <span class="nn">scrapy.linkextractors</span> <span class="kn">import</span> <span class="n">LinkExtractor</span>
<span class="kn">from</span> <span class="nn">scrapy.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>
   
<span class="kn">from</span> <span class="nn">douban.items</span> <span class="kn">import</span> <span class="n">DoubanItem</span>
   
   
<span class="k">class</span> <span class="nc">MovieSpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;movie&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;movie.douban.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;https://movie.douban.com/top250&#39;</span><span class="p">]</span>
    <span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">Rule</span><span class="p">(</span><span class="n">LinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;https://movie.douban.com/top250\?start=\d+.*&#39;</span><span class="p">))),</span>
        <span class="n">Rule</span><span class="p">(</span><span class="n">LinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;https://movie.douban.com/subject/\d+&#39;</span><span class="p">)),</span> <span class="n">callback</span><span class="o">=</span><span class="s1">&#39;parse_item&#39;</span><span class="p">),</span>
    <span class="p">)</span>
   
    <span class="k">def</span> <span class="nf">parse_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">sel</span> <span class="o">=</span> <span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">item</span> <span class="o">=</span> <span class="n">DoubanItem</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&#34;content&#34;]/h1/span[1]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&#34;content&#34;]/h1/span[2]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\((\d+)\)&#39;</span><span class="p">)</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&#34;interest_sectl&#34;]/div/p[1]/strong/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;director&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&#34;info&#34;]/span[1]/a/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;classification&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//span[@property=&#34;v:genre&#34;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s1">&#39;actor&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&#34;info&#34;]/span[3]/a[1]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">item</span>
</code></pre></td></tr></table>
</div>
</div><blockquote>
<p>说明：上面我们通过Scrapy提供的爬虫模板创建了Spider，其中的rules中的LinkExtractor对象会自动完成对新的链接的解析，该对象中有一个名为extract_link的回调方法。Scrapy支持用XPath语法和CSS选择器进行数据解析，对应的方法分别是xpath和css，上面我们使用了XPath语法对页面进行解析，如果不熟悉XPath语法可以看看后面的补充说明。</p>
</blockquote>
<p>到这里，我们已经可以通过下面的命令让爬虫运转起来。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-Shell" data-lang="Shell"><span class="o">(</span>venv<span class="o">)</span>$ scrapy crawl movie
</code></pre></td></tr></table>
</div>
</div><p>可以在控制台看到爬取到的数据，如果想将这些数据保存到文件中，可以通过<code>-o</code>参数来指定文件名，Scrapy支持我们将爬取到的数据导出成JSON、CSV、XML、pickle、marshal等格式。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-Shell" data-lang="Shell"><span class="o">(</span>venv<span class="o">)</span>$ scrapy crawl moive -o result.json
</code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>在pipelines.py中完成对数据进行持久化的操作。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-Python" data-lang="Python"><span class="c1"># -*- coding: utf-8 -*-</span>
   
<span class="c1"># Define your item pipelines here</span>
<span class="c1">#</span>
<span class="c1"># Don&#39;t forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="c1"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span class="kn">import</span> <span class="nn">pymongo</span>
   
<span class="kn">from</span> <span class="nn">scrapy.exceptions</span> <span class="kn">import</span> <span class="n">DropItem</span>
<span class="kn">from</span> <span class="nn">scrapy.conf</span> <span class="kn">import</span> <span class="n">settings</span>
<span class="kn">from</span> <span class="nn">scrapy</span> <span class="kn">import</span> <span class="n">log</span>
   
   
<span class="k">class</span> <span class="nc">DoubanPipeline</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
   
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">connection</span> <span class="o">=</span> <span class="n">pymongo</span><span class="o">.</span><span class="n">MongoClient</span><span class="p">(</span><span class="n">settings</span><span class="p">[</span><span class="s1">&#39;MONGODB_SERVER&#39;</span><span class="p">],</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;MONGODB_PORT&#39;</span><span class="p">])</span>
        <span class="n">db</span> <span class="o">=</span> <span class="n">connection</span><span class="p">[</span><span class="n">settings</span><span class="p">[</span><span class="s1">&#39;MONGODB_DB&#39;</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">collection</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">settings</span><span class="p">[</span><span class="s1">&#39;MONGODB_COLLECTION&#39;</span><span class="p">]]</span>
   
    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="c1">#Remove invalid data</span>
        <span class="n">valid</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">item</span><span class="p">:</span>
          <span class="k">if</span> <span class="ow">not</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">valid</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="k">raise</span> <span class="n">DropItem</span><span class="p">(</span><span class="s2">&#34;Missing </span><span class="si">%s</span><span class="s2"> of blogpost from </span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;url&#39;</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">valid</span><span class="p">:</span>
        <span class="c1">#Insert data into database</span>
            <span class="n">new_moive</span><span class="o">=</span><span class="p">[{</span>
                <span class="s2">&#34;name&#34;</span><span class="p">:</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                <span class="s2">&#34;year&#34;</span><span class="p">:</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                <span class="s2">&#34;score&#34;</span><span class="p">:</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span>
                <span class="s2">&#34;director&#34;</span><span class="p">:</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;director&#39;</span><span class="p">],</span>
                <span class="s2">&#34;classification&#34;</span><span class="p">:</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;classification&#39;</span><span class="p">],</span>
                <span class="s2">&#34;actor&#34;</span><span class="p">:</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;actor&#39;</span><span class="p">]</span>
            <span class="p">}]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collection</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">new_moive</span><span class="p">)</span>
            <span class="n">log</span><span class="o">.</span><span class="n">msg</span><span class="p">(</span><span class="s2">&#34;Item wrote to MongoDB database </span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span>
            <span class="p">(</span><span class="n">settings</span><span class="p">[</span><span class="s1">&#39;MONGODB_DB&#39;</span><span class="p">],</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;MONGODB_COLLECTION&#39;</span><span class="p">]),</span>
            <span class="n">level</span><span class="o">=</span><span class="n">log</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">,</span> <span class="n">spider</span><span class="o">=</span><span class="n">spider</span><span class="p">)</span> 
        <span class="k">return</span> <span class="n">item</span>
   
</code></pre></td></tr></table>
</div>
</div><p>利用Pipeline我们可以完成以下操作：</p>
<ul>
<li>清理HTML数据，验证爬取的数据。</li>
<li>丢弃重复的不必要的内容。</li>
<li>将爬取的结果进行持久化操作。</li>
</ul>
</li>
<li>
<p>修改settings.py文件对项目进行配置。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span><span class="lnt">89
</span><span class="lnt">90
</span><span class="lnt">91
</span><span class="lnt">92
</span><span class="lnt">93
</span><span class="lnt">94
</span><span class="lnt">95
</span><span class="lnt">96
</span><span class="lnt">97
</span><span class="lnt">98
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-Python" data-lang="Python"><span class="c1"># -*- coding: utf-8 -*-</span>
   
<span class="c1"># Scrapy settings for douban project</span>
<span class="c1">#</span>
<span class="c1"># For simplicity, this file contains only settings considered important or</span>
<span class="c1"># commonly used. You can find more settings consulting the documentation:</span>
<span class="c1">#</span>
<span class="c1">#     https://doc.scrapy.org/en/latest/topics/settings.html</span>
<span class="c1">#     https://doc.scrapy.org/en/latest/topics/downloader-middleware.html</span>
<span class="c1">#     https://doc.scrapy.org/en/latest/topics/spider-middleware.html</span>
   
<span class="n">BOT_NAME</span> <span class="o">=</span> <span class="s1">&#39;douban&#39;</span>
   
<span class="n">SPIDER_MODULES</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;douban.spiders&#39;</span><span class="p">]</span>
<span class="n">NEWSPIDER_MODULE</span> <span class="o">=</span> <span class="s1">&#39;douban.spiders&#39;</span>
   
   
<span class="c1"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span>
<span class="n">USER_AGENT</span> <span class="o">=</span> <span class="s1">&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.54 Safari/536.5&#39;</span>
   
<span class="c1"># Obey robots.txt rules</span>
<span class="n">ROBOTSTXT_OBEY</span> <span class="o">=</span> <span class="bp">True</span>
   
<span class="c1"># Configure maximum concurrent requests performed by Scrapy (default: 16)</span>
<span class="c1"># CONCURRENT_REQUESTS = 32</span>
   
<span class="c1"># Configure a delay for requests for the same website (default: 0)</span>
<span class="c1"># See https://doc.scrapy.org/en/latest/topics/settings.html#download-delay</span>
<span class="c1"># See also autothrottle settings and docs</span>
<span class="n">DOWNLOAD_DELAY</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">RANDOMIZE_DOWNLOAD_DELAY</span> <span class="o">=</span> <span class="bp">True</span>
<span class="c1"># The download delay setting will honor only one of:</span>
<span class="c1"># CONCURRENT_REQUESTS_PER_DOMAIN = 16</span>
<span class="c1"># CONCURRENT_REQUESTS_PER_IP = 16</span>
   
<span class="c1"># Disable cookies (enabled by default)</span>
<span class="n">COOKIES_ENABLED</span> <span class="o">=</span> <span class="bp">True</span>
   
<span class="n">MONGODB_SERVER</span> <span class="o">=</span> <span class="s1">&#39;120.77.222.217&#39;</span>
<span class="n">MONGODB_PORT</span> <span class="o">=</span> <span class="mi">27017</span>
<span class="n">MONGODB_DB</span> <span class="o">=</span> <span class="s1">&#39;douban&#39;</span>
<span class="n">MONGODB_COLLECTION</span> <span class="o">=</span> <span class="s1">&#39;movie&#39;</span>
   
<span class="c1"># Disable Telnet Console (enabled by default)</span>
<span class="c1"># TELNETCONSOLE_ENABLED = False</span>
   
<span class="c1"># Override the default request headers:</span>
<span class="c1"># DEFAULT_REQUEST_HEADERS = {</span>
<span class="c1">#   &#39;Accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#39;,</span>
<span class="c1">#   &#39;Accept-Language&#39;: &#39;en&#39;,</span>
<span class="c1"># }</span>
   
<span class="c1"># Enable or disable spider middlewares</span>
<span class="c1"># See https://doc.scrapy.org/en/latest/topics/spider-middleware.html</span>
<span class="c1"># SPIDER_MIDDLEWARES = {</span>
<span class="c1">#    &#39;douban.middlewares.DoubanSpiderMiddleware&#39;: 543,</span>
<span class="c1"># }</span>
   
<span class="c1"># Enable or disable downloader middlewares</span>
<span class="c1"># See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html</span>
<span class="c1"># DOWNLOADER_MIDDLEWARES = {</span>
<span class="c1">#    &#39;douban.middlewares.DoubanDownloaderMiddleware&#39;: 543,</span>
<span class="c1"># }</span>
   
<span class="c1"># Enable or disable extensions</span>
<span class="c1"># See https://doc.scrapy.org/en/latest/topics/extensions.html</span>
<span class="c1"># EXTENSIONS = {</span>
<span class="c1">#    &#39;scrapy.extensions.telnet.TelnetConsole&#39;: None,</span>
<span class="c1"># }</span>
   
<span class="c1"># Configure item pipelines</span>
<span class="c1"># See https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;douban.pipelines.DoubanPipeline&#39;</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
<span class="p">}</span>
   
<span class="n">LOG_LEVEL</span> <span class="o">=</span> <span class="s1">&#39;DEBUG&#39;</span>
   
<span class="c1"># Enable and configure the AutoThrottle extension (disabled by default)</span>
<span class="c1"># See https://doc.scrapy.org/en/latest/topics/autothrottle.html</span>
<span class="c1">#AUTOTHROTTLE_ENABLED = True</span>
<span class="c1"># The initial download delay</span>
<span class="c1">#AUTOTHROTTLE_START_DELAY = 5</span>
<span class="c1"># The maximum download delay to be set in case of high latencies</span>
<span class="c1">#AUTOTHROTTLE_MAX_DELAY = 60</span>
<span class="c1"># The average number of requests Scrapy should be sending in parallel to</span>
<span class="c1"># each remote server</span>
<span class="c1">#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0</span>
<span class="c1"># Enable showing throttling stats for every response received:</span>
<span class="c1">#AUTOTHROTTLE_DEBUG = False</span>
   
<span class="c1"># Enable and configure HTTP caching (disabled by default)</span>
<span class="c1"># See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings</span>
<span class="n">HTTPCACHE_ENABLED</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">HTTPCACHE_EXPIRATION_SECS</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">HTTPCACHE_DIR</span> <span class="o">=</span> <span class="s1">&#39;httpcache&#39;</span>
<span class="n">HTTPCACHE_IGNORE_HTTP_CODES</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">HTTPCACHE_STORAGE</span> <span class="o">=</span> <span class="s1">&#39;scrapy.extensions.httpcache.FilesystemCacheStorage&#39;</span>
</code></pre></td></tr></table>
</div>
</div></li>
</ol>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2017-01-15</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/scrapy%E5%85%A5%E9%97%A8/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="http://www.nishinonanase.xyz/scrapy%E5%85%A5%E9%97%A8/" data-title="Scrapy入门" data-hashtags="技术要点,爬虫"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="http://www.nishinonanase.xyz/scrapy%E5%85%A5%E9%97%A8/" data-hashtag="技术要点"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Hacker News" data-sharer="hackernews" data-url="http://www.nishinonanase.xyz/scrapy%E5%85%A5%E9%97%A8/" data-title="Scrapy入门"><i class="fab fa-hacker-news fa-fw"></i></a><a href="javascript:void(0);" title="分享到 Line" data-sharer="line" data-url="http://www.nishinonanase.xyz/scrapy%E5%85%A5%E9%97%A8/" data-title="Scrapy入门"><i data-svg-src="/lib/simple-icons/icons/line.min.svg"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="http://www.nishinonanase.xyz/scrapy%E5%85%A5%E9%97%A8/" data-title="Scrapy入门" data-ralateuid="5146819796"><i class="fab fa-weibo fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9/">技术要点</a>,&nbsp;<a href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/gil%E5%85%A8%E5%B1%80%E8%A7%A3%E9%87%8A%E5%99%A8%E9%94%81/" class="prev" rel="prev" title="GIL全局解释器锁"><i class="fas fa-angle-left fa-fw"></i>GIL全局解释器锁</a>
            <a href="/jwt%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6/" class="next" rel="next" title="JWT认证机制">JWT认证机制<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="valine" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://valine.js.org/">Valine</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">由<a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.68.3">Hugo</a> 驱动 | 主题-<a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a> | 乃木坂46
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2016 - 2020</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">书兰</a></span><span class="icp-splitter">&nbsp;|&nbsp;</span><br class="icp-br"/>
                    <span class="icp"><a target="_blank" href="https://weibo.com/u/7266809683">欢迎微博关注@西野七瀬</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/valine/valine.min.css"><link rel="stylesheet" href="/lib/lightgallery/lightgallery.min.css"><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><script type="text/javascript" src="/lib/valine/Valine.min.js"></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/twemoji/twemoji.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lightgallery.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-thumbnail.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-zoom.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{"valine":{"appId":"pYP10MBmXAHPlpAH6etQREAF-gzGzoHsz","appKey":"U85Rh0XAdTAh3amYgmCcv8no","avatar":"mm","el":"#valine","emojiCDN":"https://cdn.jsdelivr.net/npm/emoji-datasource-google@5.0.1/img/google/64/","emojiMaps":{"100":"1f4af.png","alien":"1f47d.png","anger":"1f4a2.png","angry":"1f620.png","anguished":"1f627.png","astonished":"1f632.png","black_heart":"1f5a4.png","blue_heart":"1f499.png","blush":"1f60a.png","bomb":"1f4a3.png","boom":"1f4a5.png","broken_heart":"1f494.png","brown_heart":"1f90e.png","clown_face":"1f921.png","cold_face":"1f976.png","cold_sweat":"1f630.png","confounded":"1f616.png","confused":"1f615.png","cry":"1f622.png","crying_cat_face":"1f63f.png","cupid":"1f498.png","dash":"1f4a8.png","disappointed":"1f61e.png","disappointed_relieved":"1f625.png","dizzy":"1f4ab.png","dizzy_face":"1f635.png","drooling_face":"1f924.png","exploding_head":"1f92f.png","expressionless":"1f611.png","face_vomiting":"1f92e.png","face_with_cowboy_hat":"1f920.png","face_with_hand_over_mouth":"1f92d.png","face_with_head_bandage":"1f915.png","face_with_monocle":"1f9d0.png","face_with_raised_eyebrow":"1f928.png","face_with_rolling_eyes":"1f644.png","face_with_symbols_on_mouth":"1f92c.png","face_with_thermometer":"1f912.png","fearful":"1f628.png","flushed":"1f633.png","frowning":"1f626.png","ghost":"1f47b.png","gift_heart":"1f49d.png","green_heart":"1f49a.png","grimacing":"1f62c.png","grin":"1f601.png","grinning":"1f600.png","hankey":"1f4a9.png","hear_no_evil":"1f649.png","heart":"2764-fe0f.png","heart_decoration":"1f49f.png","heart_eyes":"1f60d.png","heart_eyes_cat":"1f63b.png","heartbeat":"1f493.png","heartpulse":"1f497.png","heavy_heart_exclamation_mark_ornament":"2763-fe0f.png","hole":"1f573-fe0f.png","hot_face":"1f975.png","hugging_face":"1f917.png","hushed":"1f62f.png","imp":"1f47f.png","innocent":"1f607.png","japanese_goblin":"1f47a.png","japanese_ogre":"1f479.png","joy":"1f602.png","joy_cat":"1f639.png","kiss":"1f48b.png","kissing":"1f617.png","kissing_cat":"1f63d.png","kissing_closed_eyes":"1f61a.png","kissing_heart":"1f618.png","kissing_smiling_eyes":"1f619.png","laughing":"1f606.png","left_speech_bubble":"1f5e8-fe0f.png","love_letter":"1f48c.png","lying_face":"1f925.png","mask":"1f637.png","money_mouth_face":"1f911.png","nauseated_face":"1f922.png","nerd_face":"1f913.png","neutral_face":"1f610.png","no_mouth":"1f636.png","open_mouth":"1f62e.png","orange_heart":"1f9e1.png","partying_face":"1f973.png","pensive":"1f614.png","persevere":"1f623.png","pleading_face":"1f97a.png","pouting_cat":"1f63e.png","purple_heart":"1f49c.png","rage":"1f621.png","relaxed":"263a-fe0f.png","relieved":"1f60c.png","revolving_hearts":"1f49e.png","right_anger_bubble":"1f5ef-fe0f.png","robot_face":"1f916.png","rolling_on_the_floor_laughing":"1f923.png","scream":"1f631.png","scream_cat":"1f640.png","see_no_evil":"1f648.png","shushing_face":"1f92b.png","skull":"1f480.png","skull_and_crossbones":"2620-fe0f.png","sleeping":"1f634.png","sleepy":"1f62a.png","slightly_frowning_face":"1f641.png","slightly_smiling_face":"1f642.png","smile":"1f604.png","smile_cat":"1f638.png","smiley":"1f603.png","smiley_cat":"1f63a.png","smiling_face_with_3_hearts":"1f970.png","smiling_imp":"1f608.png","smirk":"1f60f.png","smirk_cat":"1f63c.png","sneezing_face":"1f927.png","sob":"1f62d.png","space_invader":"1f47e.png","sparkling_heart":"1f496.png","speak_no_evil":"1f64a.png","speech_balloon":"1f4ac.png","star-struck":"1f929.png","stuck_out_tongue":"1f61b.png","stuck_out_tongue_closed_eyes":"1f61d.png","stuck_out_tongue_winking_eye":"1f61c.png","sunglasses":"1f60e.png","sweat":"1f613.png","sweat_drops":"1f4a6.png","sweat_smile":"1f605.png","thinking_face":"1f914.png","thought_balloon":"1f4ad.png","tired_face":"1f62b.png","triumph":"1f624.png","two_hearts":"1f495.png","unamused":"1f612.png","upside_down_face":"1f643.png","weary":"1f629.png","white_frowning_face":"2639-fe0f.png","white_heart":"1f90d.png","wink":"1f609.png","woozy_face":"1f974.png","worried":"1f61f.png","yawning_face":"1f971.png","yellow_heart":"1f49b.png","yum":"1f60b.png","zany_face":"1f92a.png","zipper_mouth_face":"1f910.png","zzz":"1f4a4.png"},"enableQQ":false,"highlight":true,"lang":"zh-cn","pageSize":10,"placeholder":"你的评论 ...","recordIP":true,"visitor":true}},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"twemoji":true};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
